# Q. - Creepypasta Scraper

A modern web application for scraping and browsing creepypasta stories from the Creepypasta Wiki.

## Features

- ğŸ•·ï¸ **Web Scraping**: Scrapes stories from [Creepypasta Wiki All Pages](https://creepypasta.fandom.com/wiki/Special:AllPages)
- ğŸ¨ **Modern UI**: Black/white/red color scheme with responsive design
- ğŸ“Š **Real-time Progress**: Live progress tracking during scraping
- ğŸ·ï¸ **Genre Classification**: Automatic genre detection and filtering
- ğŸ“± **Responsive**: Works on desktop and mobile devices
- ğŸ’¾ **Data Export**: JSONL output with optional MongoDB storage

## Quick Start

### 1. Install Dependencies
```bash
cd "/Users/ahnaflabib/Documents/Projects/mime."
source .venv/bin/activate
pip install -r requirements.txt  # If you create one
```

### 2. Run the Web Application
```bash
python app.py
```

### 3. Open in Browser
Navigate to: http://localhost:5000

### 4. Start Scraping
- Click the "Start Scraping" button
- Watch real-time progress
- Browse stories by genre
- Click stories to read full content

## Manual Scraping (Command Line)

```bash
# Scrape 50 stories
scrapy crawl creepypasta -s CLOSESPIDER_ITEMCOUNT=50 -s ROBOTSTXT_OBEY=False

# Scrape with MongoDB
scrapy crawl creepypasta -s MONGODB_ENABLED=True -s MONGODB_URI="mongodb://localhost:27017"
```

## Project Structure

```
mime./
â”œâ”€â”€ app.py                          # Flask web application
â”œâ”€â”€ mime_scraper/                   # Scrapy project
â”‚   â”œâ”€â”€ items.py                    # Story data schema
â”‚   â”œâ”€â”€ pipelines.py                # JSON & MongoDB pipelines
â”‚   â”œâ”€â”€ middlewares.py              # User-agent rotation
â”‚   â”œâ”€â”€ settings.py                 # Scrapy configuration
â”‚   â””â”€â”€ spiders/
â”‚       â””â”€â”€ creepypasta_spider.py  # Main scraping logic
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                  # Main web page
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css              # Styling
â”‚   â””â”€â”€ js/app.js                  # Frontend JavaScript
â”œâ”€â”€ outputs/                        # Scraped data (JSONL files)
â””â”€â”€ scrapy.cfg                      # Scrapy configuration
```

## API Endpoints

- `GET /` - Main web interface
- `POST /api/start-scraping` - Start scraping process
- `GET /api/status` - Get scraping status
- `GET /api/stories` - Get all scraped stories
- `GET /api/stories/<genre>` - Get stories by genre

## Configuration

### Scrapy Settings
- **Rate Limiting**: 2-second delays between requests
- **User Agent Rotation**: Multiple browser user agents
- **AutoThrottle**: Enabled for respectful scraping
- **Output**: JSONL files in `outputs/` directory

### MongoDB (Optional)
Set in `mime_scraper/settings.py`:
```python
MONGODB_ENABLED = True
MONGODB_URI = "mongodb://localhost:27017"
MONGODB_DATABASE = "mime"
MONGODB_COLLECTION = "creepypasta"
```

## Genre Classification

Stories are automatically classified into genres based on tags:
- **Supernatural**: Ghosts, Demons, Monsters
- **Psychological**: Mental Illness, Dreams, Nightmares
- **Creature**: Vampires, Werewolves, Zombies
- **Sci-Fi**: Aliens, Technology, Space
- **Digital**: Internet, Video Games, Computers
- **Crime**: Serial Killers, Murder
- **Urban Legend**: Folklore, Mythology
- And more...

## Technology Stack

- **Backend**: Python, Flask, Scrapy
- **Frontend**: HTML5, CSS3, JavaScript (ES6+)
- **Database**: MongoDB (optional)
- **Styling**: Custom CSS with Inter font
- **Icons**: Unicode emojis

## License

This project is for educational purposes. Please respect the Creepypasta Wiki's terms of service and robots.txt when scraping.

